{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"riffq is a toolkit in python for building PostgreSQL wire-compatible databases. It allows you to serve data from Python over the PostgreSQL protocol. About the project So in other words riffq is postgresql wire compatible frontend layer for your databases/data in python. We also have a catalog emulation system in rust with datafusion. The Python package lives under pysrc/riffq , while the Rust crate powers performance-critical features src/ . Use the navigation on the left to explore the guides: Learn how to install and configure Riffq in the Getting Started section. Browse frequently asked questions in the FAQ . Review the latest updates in the Changelog . Dive into the generated API reference for details on public classes and functions. Quick links Project repository Issue tracker","title":"Home"},{"location":"#about-the-project","text":"So in other words riffq is postgresql wire compatible frontend layer for your databases/data in python. We also have a catalog emulation system in rust with datafusion. The Python package lives under pysrc/riffq , while the Rust crate powers performance-critical features src/ . Use the navigation on the left to explore the guides: Learn how to install and configure Riffq in the Getting Started section. Browse frequently asked questions in the FAQ . Review the latest updates in the Changelog . Dive into the generated API reference for details on public classes and functions.","title":"About the project"},{"location":"#quick-links","text":"Project repository Issue tracker","title":"Quick links"},{"location":"api-reference/","text":"The API reference is generated automatically from the Python package under pysrc/riffq . To refresh the documentation, run: make docs riffq Riffq Python bindings and high-level server interface. This package exposes a lightweight Python API around the Rust server core ( Server ) and provides utilities for building custom query backends. Exports: Server : Low-level Rust server class (from the compiled extension). BaseConnection : Abstract base to implement your own connection logic. RiffqServer : Convenience wrapper that wires callbacks to Server and manages connection instances. Modules: Name Description connection Connection primitives and the high-level server wrapper. helpers Helper utilities for building Arrow results. Modules riffq.connection riffq.connection Connection primitives and the high-level server wrapper. This module defines two main concepts: BaseConnection : an abstract per client connection that you subclass to implement authentication, query execution and lifecycle hooks. RiffqServer : a small orchestrator that owns the Rust Server , creates BaseConnection instances on demand, and forwards events to them. Callbacks The Rust layer invokes Python callbacks with a callback function argument that must be called to deliver results back to the server. Query callbacks accept an Arrow C Stream capsule for result sets, or an error. Classes: Name Description BaseConnection Abstract per client connection. RiffqServer High level server that manages connections and forwards events. BaseConnection Abstract per client connection. Subclass this to implement authentication and query handling. One instance is created per remote client and reused for its lifecycle. Parameters: Name Type Description Default conn_id int Unique identifier assigned by the server. required executor ThreadPoolExecutor Thread pool used for offloading blocking work. required Methods: Name Description arrow_batch Create a RecordBatchReader from arrays and names. handle_auth Authenticate a client. handle_connect Handle successful TCP connection establishment. handle_disconnect Handle client disconnect cleanup. handle_query Execute a SQL statement and return results. send_reader Send a PyArrow reader back to the server. arrow_batch(values, names) Create a RecordBatchReader from arrays and names. Parameters: Name Type Description Default values Sequence [ Array ] Sequence of pyarrow.Array values, one per column. required names Sequence [ str ] Column names aligned with values . required Returns: Type Description RecordBatchReader pyarrow.RecordBatchReader: Reader yielding a single batch. handle_auth(user, password, host, database = None , callback = lambda * a, ** k: None ) abstractmethod Authenticate a client. Parameters: Name Type Description Default user str Username supplied by the client. required password str Password supplied by the client. required host str Requested host/server name. required database Optional [ str ] Optional initial database name. None callback Callable [..., None] Invoke with True / False or raise to signal errors. lambda *a, **k: None handle_connect(ip, port, callback = lambda * a, ** k: None ) Handle successful TCP connection establishment. Parameters: Name Type Description Default ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Invoke with True to accept or raise to reject. lambda *a, **k: None handle_disconnect(ip, port, callback = lambda * a, ** k: None ) Handle client disconnect cleanup. Parameters: Name Type Description Default ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Invoke with True to acknowledge. lambda *a, **k: None handle_query(sql, callback = lambda * a, ** k: None , ** kwargs) abstractmethod Execute a SQL statement and return results. Implementations should produce a pyarrow.RecordBatchReader and pass its Arrow C Stream capsule to callback . To indicate an error, raise an exception or pass an error to the callback if supported. Parameters: Name Type Description Default sql str The SQL text to execute. required callback Callable [..., None] Callable to receive an Arrow C Stream capsule. lambda *a, **k: None **kwargs Any Transport or driver specific flags (e.g., timeouts). {} send_reader(reader, callback) Send a PyArrow reader back to the server. Converts a pyarrow.RecordBatchReader (or compatible) into an Arrow C Stream capsule and passes it to the provided callback . Parameters: Name Type Description Default reader Any A RecordBatchReader (or object exposing __arrow_c_stream__ ). required callback Callable [..., None] Callable receiving a single C Stream capsule object. required RiffqServer High level server that manages connections and forwards events. Parameters: Name Type Description Default listen_addr str Address string (e.g., \"127.0.0.1:5432\") to bind. required connection_cls Type [ BaseConnection ] Subclass of BaseConnection used per client. BaseConnection Methods: Name Description get_connection Get or create the BaseConnection for a given connection_id . handle_auth Forward an authentication request to the connection instance. handle_connect Forward a connect notification to the connection instance. handle_disconnect Forward a disconnect notification and release the connection. handle_query Forward a query to the connection instance. register_database Register a logical database for catalog emulation. register_schema Register a schema under a database for catalog emulation. register_table Register a table and its columns for catalog emulation. set_tls Enable TLS with certificate and key files. start Start the server event loop. get_connection(connection_id) Get or create the BaseConnection for a given connection_id . handle_auth(connection_id, user, password, host, database = None , callback = lambda * a, ** k: None ) Forward an authentication request to the connection instance. Parameters: Name Type Description Default connection_id int Server assigned identifier for this client. required user str Username supplied by the client. required password str Password supplied by the client. required host str Requested host/server name. required database Optional [ str ] Optional initial database name. None callback Callable [..., None] Function to receive auth result. lambda *a, **k: None handle_connect(connection_id, ip, port, callback = lambda * a, ** k: None ) Forward a connect notification to the connection instance. Parameters: Name Type Description Default connection_id int Server assigned identifier for this client. required ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Function to acknowledge handling. lambda *a, **k: None handle_disconnect(connection_id, ip, port, callback = lambda * a, ** k: None ) Forward a disconnect notification and release the connection. Parameters: Name Type Description Default connection_id int Server assigned identifier for this client. required ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Function to acknowledge handling. lambda *a, **k: None handle_query(sql, callback, connection_id = None , ** kwargs) Forward a query to the connection instance. Parameters: Name Type Description Default sql str SQL string to execute. required callback Callable [..., None] Function to receive an Arrow C Stream capsule. required connection_id Optional [ int ] Server assigned identifier for this client. None **kwargs Any Driver specific flags forwarded as is. {} register_database(database_name) Register a logical database for catalog emulation. When start(catalog_emulation=True) is used, the server responds to client metadata queries (pg_catalog) using entries registered via these helpers. Parameters: Name Type Description Default database_name str Name of the database to expose via pg_catalog . required register_schema(database_name, schema_name) Register a schema under a database for catalog emulation. Parameters: Name Type Description Default database_name str Existing database registered via register_database . required schema_name str Schema name to add under the database. required register_table(database_name, schema_name, table_name, columns) Register a table and its columns for catalog emulation. The columns argument describes each column as a single key dict mapping the column name to a small descriptor: { \"name\": { \"type\": <str>, \"nullable\": <bool> } } . Supported type strings are aligned with riffq.helpers.to_arrow mapping and include: int , float , bool , str / string , date , datetime . Parameters: Name Type Description Default database_name str Target database name. required schema_name str Target schema name. required table_name str Table name to register. required columns List [ Dict [ str , Dict [ str , Any ]]] Column descriptors as described above. required set_tls(crt, key) Enable TLS with certificate and key files. Parameters: Name Type Description Default crt str Path to PEM encoded server certificate. required key str Path to PEM encoded private key. required Raises: Type Description OSError If crt or key does not exist. start(tls = False , catalog_emulation = False , server_version = None ) Start the server event loop. Parameters: Name Type Description Default tls bool Turn ssl/tls on or off. When tls is true, remember you need to set server.set_tls(cert_path, key_path) False catalog_emulation bool Turn pg_catalog & information_schema query handling by riffq. False server_version Optional [ str ] Server version string eg: \"17.6 (Homebrew)\" If you omit this, we use hardcoded string in src/lib.rs None Returns: None. Starts the underlying Rust server loop. riffq.helpers riffq.helpers Helper utilities for building Arrow results. Currently provides to_arrow for constructing an Arrow C Stream from a simple schema description and row data. This is handy for small, programmatic results without depending on a database engine. Functions: Name Description to_arrow Build an Arrow C Stream from schema and rows for regular python values to_arrow(schema_desc, rows) Build an Arrow C Stream from schema and rows for regular python values The schema is a list of dicts like { \"name\": str, \"type\": str } where type is one of: int , float , bool , str / string , date , datetime . Rows are sequences whose positional items match the schema order. Example usage: callback(to_arrow([{\"name\": \"val\", \"type\": \"int\"}], [ [1], [2] ])) Parameters: Name Type Description Default schema_desc list [ dict ] Column descriptors in display order. required rows list Iterable of row sequences aligned to schema_desc . required Returns: Type Description PyCapsule A PyCapsule containing an Arrow C Stream suitable for returning to the PyCapsule server callback.","title":"API Reference"},{"location":"api-reference/#riffq","text":"Riffq Python bindings and high-level server interface. This package exposes a lightweight Python API around the Rust server core ( Server ) and provides utilities for building custom query backends. Exports: Server : Low-level Rust server class (from the compiled extension). BaseConnection : Abstract base to implement your own connection logic. RiffqServer : Convenience wrapper that wires callbacks to Server and manages connection instances. Modules: Name Description connection Connection primitives and the high-level server wrapper. helpers Helper utilities for building Arrow results.","title":"riffq"},{"location":"api-reference/#modules","text":"","title":"Modules"},{"location":"api-reference/#riffqconnection","text":"","title":"riffq.connection"},{"location":"api-reference/#riffq.connection","text":"Connection primitives and the high-level server wrapper. This module defines two main concepts: BaseConnection : an abstract per client connection that you subclass to implement authentication, query execution and lifecycle hooks. RiffqServer : a small orchestrator that owns the Rust Server , creates BaseConnection instances on demand, and forwards events to them. Callbacks The Rust layer invokes Python callbacks with a callback function argument that must be called to deliver results back to the server. Query callbacks accept an Arrow C Stream capsule for result sets, or an error. Classes: Name Description BaseConnection Abstract per client connection. RiffqServer High level server that manages connections and forwards events.","title":"connection"},{"location":"api-reference/#riffq.connection.BaseConnection","text":"Abstract per client connection. Subclass this to implement authentication and query handling. One instance is created per remote client and reused for its lifecycle. Parameters: Name Type Description Default conn_id int Unique identifier assigned by the server. required executor ThreadPoolExecutor Thread pool used for offloading blocking work. required Methods: Name Description arrow_batch Create a RecordBatchReader from arrays and names. handle_auth Authenticate a client. handle_connect Handle successful TCP connection establishment. handle_disconnect Handle client disconnect cleanup. handle_query Execute a SQL statement and return results. send_reader Send a PyArrow reader back to the server.","title":"BaseConnection"},{"location":"api-reference/#riffq.connection.BaseConnection.arrow_batch","text":"Create a RecordBatchReader from arrays and names. Parameters: Name Type Description Default values Sequence [ Array ] Sequence of pyarrow.Array values, one per column. required names Sequence [ str ] Column names aligned with values . required Returns: Type Description RecordBatchReader pyarrow.RecordBatchReader: Reader yielding a single batch.","title":"arrow_batch"},{"location":"api-reference/#riffq.connection.BaseConnection.handle_auth","text":"Authenticate a client. Parameters: Name Type Description Default user str Username supplied by the client. required password str Password supplied by the client. required host str Requested host/server name. required database Optional [ str ] Optional initial database name. None callback Callable [..., None] Invoke with True / False or raise to signal errors. lambda *a, **k: None","title":"handle_auth"},{"location":"api-reference/#riffq.connection.BaseConnection.handle_connect","text":"Handle successful TCP connection establishment. Parameters: Name Type Description Default ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Invoke with True to accept or raise to reject. lambda *a, **k: None","title":"handle_connect"},{"location":"api-reference/#riffq.connection.BaseConnection.handle_disconnect","text":"Handle client disconnect cleanup. Parameters: Name Type Description Default ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Invoke with True to acknowledge. lambda *a, **k: None","title":"handle_disconnect"},{"location":"api-reference/#riffq.connection.BaseConnection.handle_query","text":"Execute a SQL statement and return results. Implementations should produce a pyarrow.RecordBatchReader and pass its Arrow C Stream capsule to callback . To indicate an error, raise an exception or pass an error to the callback if supported. Parameters: Name Type Description Default sql str The SQL text to execute. required callback Callable [..., None] Callable to receive an Arrow C Stream capsule. lambda *a, **k: None **kwargs Any Transport or driver specific flags (e.g., timeouts). {}","title":"handle_query"},{"location":"api-reference/#riffq.connection.BaseConnection.send_reader","text":"Send a PyArrow reader back to the server. Converts a pyarrow.RecordBatchReader (or compatible) into an Arrow C Stream capsule and passes it to the provided callback . Parameters: Name Type Description Default reader Any A RecordBatchReader (or object exposing __arrow_c_stream__ ). required callback Callable [..., None] Callable receiving a single C Stream capsule object. required","title":"send_reader"},{"location":"api-reference/#riffq.connection.RiffqServer","text":"High level server that manages connections and forwards events. Parameters: Name Type Description Default listen_addr str Address string (e.g., \"127.0.0.1:5432\") to bind. required connection_cls Type [ BaseConnection ] Subclass of BaseConnection used per client. BaseConnection Methods: Name Description get_connection Get or create the BaseConnection for a given connection_id . handle_auth Forward an authentication request to the connection instance. handle_connect Forward a connect notification to the connection instance. handle_disconnect Forward a disconnect notification and release the connection. handle_query Forward a query to the connection instance. register_database Register a logical database for catalog emulation. register_schema Register a schema under a database for catalog emulation. register_table Register a table and its columns for catalog emulation. set_tls Enable TLS with certificate and key files. start Start the server event loop.","title":"RiffqServer"},{"location":"api-reference/#riffq.connection.RiffqServer.get_connection","text":"Get or create the BaseConnection for a given connection_id .","title":"get_connection"},{"location":"api-reference/#riffq.connection.RiffqServer.handle_auth","text":"Forward an authentication request to the connection instance. Parameters: Name Type Description Default connection_id int Server assigned identifier for this client. required user str Username supplied by the client. required password str Password supplied by the client. required host str Requested host/server name. required database Optional [ str ] Optional initial database name. None callback Callable [..., None] Function to receive auth result. lambda *a, **k: None","title":"handle_auth"},{"location":"api-reference/#riffq.connection.RiffqServer.handle_connect","text":"Forward a connect notification to the connection instance. Parameters: Name Type Description Default connection_id int Server assigned identifier for this client. required ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Function to acknowledge handling. lambda *a, **k: None","title":"handle_connect"},{"location":"api-reference/#riffq.connection.RiffqServer.handle_disconnect","text":"Forward a disconnect notification and release the connection. Parameters: Name Type Description Default connection_id int Server assigned identifier for this client. required ip str Remote peer IP address. required port int Remote peer port. required callback Callable [..., None] Function to acknowledge handling. lambda *a, **k: None","title":"handle_disconnect"},{"location":"api-reference/#riffq.connection.RiffqServer.handle_query","text":"Forward a query to the connection instance. Parameters: Name Type Description Default sql str SQL string to execute. required callback Callable [..., None] Function to receive an Arrow C Stream capsule. required connection_id Optional [ int ] Server assigned identifier for this client. None **kwargs Any Driver specific flags forwarded as is. {}","title":"handle_query"},{"location":"api-reference/#riffq.connection.RiffqServer.register_database","text":"Register a logical database for catalog emulation. When start(catalog_emulation=True) is used, the server responds to client metadata queries (pg_catalog) using entries registered via these helpers. Parameters: Name Type Description Default database_name str Name of the database to expose via pg_catalog . required","title":"register_database"},{"location":"api-reference/#riffq.connection.RiffqServer.register_schema","text":"Register a schema under a database for catalog emulation. Parameters: Name Type Description Default database_name str Existing database registered via register_database . required schema_name str Schema name to add under the database. required","title":"register_schema"},{"location":"api-reference/#riffq.connection.RiffqServer.register_table","text":"Register a table and its columns for catalog emulation. The columns argument describes each column as a single key dict mapping the column name to a small descriptor: { \"name\": { \"type\": <str>, \"nullable\": <bool> } } . Supported type strings are aligned with riffq.helpers.to_arrow mapping and include: int , float , bool , str / string , date , datetime . Parameters: Name Type Description Default database_name str Target database name. required schema_name str Target schema name. required table_name str Table name to register. required columns List [ Dict [ str , Dict [ str , Any ]]] Column descriptors as described above. required","title":"register_table"},{"location":"api-reference/#riffq.connection.RiffqServer.set_tls","text":"Enable TLS with certificate and key files. Parameters: Name Type Description Default crt str Path to PEM encoded server certificate. required key str Path to PEM encoded private key. required Raises: Type Description OSError If crt or key does not exist.","title":"set_tls"},{"location":"api-reference/#riffq.connection.RiffqServer.start","text":"Start the server event loop. Parameters: Name Type Description Default tls bool Turn ssl/tls on or off. When tls is true, remember you need to set server.set_tls(cert_path, key_path) False catalog_emulation bool Turn pg_catalog & information_schema query handling by riffq. False server_version Optional [ str ] Server version string eg: \"17.6 (Homebrew)\" If you omit this, we use hardcoded string in src/lib.rs None Returns: None. Starts the underlying Rust server loop.","title":"start"},{"location":"api-reference/#riffqhelpers","text":"","title":"riffq.helpers"},{"location":"api-reference/#riffq.helpers","text":"Helper utilities for building Arrow results. Currently provides to_arrow for constructing an Arrow C Stream from a simple schema description and row data. This is handy for small, programmatic results without depending on a database engine. Functions: Name Description to_arrow Build an Arrow C Stream from schema and rows for regular python values","title":"helpers"},{"location":"api-reference/#riffq.helpers.to_arrow","text":"Build an Arrow C Stream from schema and rows for regular python values The schema is a list of dicts like { \"name\": str, \"type\": str } where type is one of: int , float , bool , str / string , date , datetime . Rows are sequences whose positional items match the schema order. Example usage: callback(to_arrow([{\"name\": \"val\", \"type\": \"int\"}], [ [1], [2] ])) Parameters: Name Type Description Default schema_desc list [ dict ] Column descriptors in display order. required rows list Iterable of row sequences aligned to schema_desc . required Returns: Type Description PyCapsule A PyCapsule containing an Arrow C Stream suitable for returning to the PyCapsule server callback.","title":"to_arrow"},{"location":"catalog/","text":"Riffq can emulate PostgreSQL system catalogs (pg_catalog, information_schema) so client tools can enumerate databases, schemas, tables, and columns. At a high level: - Define metadata with register_database , register_schema , register_table . - Start your server with catalog_emulation=True . Behind the scenes, Riffq uses a Rust helper crate pg_catalog_rs to answer catalog queries efficiently. Quick Start import riffq class Connection (riffq . BaseConnection): def handle_query ( self , sql, callback = callable , ** kwargs): # return some rows or a command tag here ... server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) # 1) Register a database server . register_database( \"mydb\" ) # 2) Register a schema within the database server . register_schema( \"mydb\" , \"public\" ) # 3) Register a table and its columns server . register_table( \"mydb\" , \"public\" , \"users\" , [ { \"id\" : { \"type\" : \"int\" , \"nullable\" : False }}, { \"name\" : { \"type\" : \"string\" , \"nullable\" : True }}, { \"created_at\" : { \"type\" : \"datetime\" , \"nullable\" : False }}, ], ) server . start(catalog_emulation = True ) Column Types Supported column type strings align with the Arrow types used by Riffq: int , float , bool , string / str , date , datetime These types inform clients about your table shape; your actual query results can be produced by any engine (DuckDB, Polars, Pandas, etc.) as Arrow. Discovering From an Engine For real data sources, enumerate schemas/tables/columns dynamically and register them. For example with DuckDB (pseudo-code): def map_type (duckdb_type: str ) -> str : t = duckdb_type . upper() if \"INT\" in t: return \"int\" if any (x in t for x in [ \"DOUBLE\" , \"DECIMAL\" , \"REAL\" , \"FLOAT\" ]): return \"float\" if \"BOOL\" in t: return \"bool\" if t == \"DATE\" : return \"date\" if \"TIMESTAMP\" in t or \"DATETIME\" in t: return \"datetime\" return \"string\" server . register_database( \"duckdb\" ) for schema_name, table_name in list_tables_from_duckdb(): server . register_schema( \"duckdb\" , schema_name) columns = [] for col_name, dt, is_nullable in list_columns(schema_name, table_name): columns . append({col_name: { \"type\" : map_type(dt), \"nullable\" : is_nullable}}) server . register_table( \"duckdb\" , schema_name, table_name, columns) server . start(catalog_emulation = True ) Examples For a minimal end-to-end example that registers a database, schema, and table and asserts they appear via pg_catalog , see: tests/test_register_catalog.py def main (): server = riffq . RiffqServer( \"127.0.0.1:5444\" , connection_cls = Connection) # Register catalog: logical databases redis0..redis2 (limited for illustration). # Under each, register schema \"public\" and expose each Redis hash key as a # table with (key,value). Increase the range below in real deployments. # schema \"public\" and expose each Redis hash key as a table with (key,value). for db_index in range ( 3 ): db_name = f\"redis { db_index } \" r = redis . Redis(host = \"localhost\" , port =6379 , db = db_index, password = None , decode_responses = True ) server . register_database(db_name) server . register_schema(db_name, \"public\" ) # Discover only hash keys. Uses SCAN TYPE hash (server-side filter) # so we don't issue a TYPE per key. Still a best-effort scan. for k in r . scan_iter(match = \"*\" , _type = \"hash\" ): server . register_table( db_name, \"public\" , str (k), [ { \"key\" : { \"type\" : \"string\" , \"nullable\" : False }}, { \"value\" : { \"type\" : \"string\" , \"nullable\" : True }}, ], ) When you start the server and connect with psql you can see the tables user=> \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+-------------+-------------+------------------- postgres | postgres | UTF8 | nl_NL.UTF-8 | nl_NL.UTF-8 | redis0 | postgres | UTF8 | C | C | redis1 | postgres | UTF8 | C | C | redis2 | postgres | UTF8 | C | C | template0 | postgres | UTF8 | nl_NL.UTF-8 | nl_NL.UTF-8 | template1 | postgres | UTF8 | nl_NL.UTF-8 | nl_NL.UTF-8 | (6 rows) user=> \\c redis0 Password: psql (14.17 (Homebrew), server 17.4.0) WARNING: psql major version 14, server major version 17. Some psql features might not work. You are now connected to database \"redis0\" as user \"user\". redis0=> \\dt List of relations Schema | Name | Type | Owner --------+--------+-------+---------- public | myhash | table | postgres public | test | table | postgres public | test2 | table | postgres public | test3 | table | postgres (4 rows) redis0=> \\d myhash Table \"public.myhash\" Column | Type | Collation | Nullable | Default --------+------+-----------+----------+--------- key | text | | not null | value | text | | | redis0=> \\d myhash Table \"public.myhash\" Column | Type | Collation | Nullable | Default --------+------+-----------+----------+--------- key | text | | not null | value | text | | | ; pg_catalog_rs has all pg_catalog tables ; for example you can select tables directly from pg_class redis0=> SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE c.relkind = 'r' AND n.nspname = 'public'; relname --------- myhash test2 test test3 (4 rows) ; or you can use ::regclass or ::oid type conversions as in ; real postgresql pg_catalog redis0=> SELECT oid,relname,reltype,relnamespace FROM pg_class WHERE oid = 'myhash'::oid; oid | relname | reltype | relnamespace -------+---------+---------+-------------- 50010 | myhash | 50011 | 2200 (1 row) API Reference Register a logical database name RiffqServer . register_database(database_name: str ) -> None : Register a schema under a previously registered database. RiffqServer . register_schema(database_name: str , schema_name: str ) -> None : Register a table and its columns. Each column is { name: {\"type\": <str>, \"nullable\": <bool>} } . RiffqServer . register_table(database_name: str , schema_name: str , table_name: str , columns: list [ dict ]) -> None :","title":"Catalog Emulation"},{"location":"catalog/#quick-start","text":"import riffq class Connection (riffq . BaseConnection): def handle_query ( self , sql, callback = callable , ** kwargs): # return some rows or a command tag here ... server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) # 1) Register a database server . register_database( \"mydb\" ) # 2) Register a schema within the database server . register_schema( \"mydb\" , \"public\" ) # 3) Register a table and its columns server . register_table( \"mydb\" , \"public\" , \"users\" , [ { \"id\" : { \"type\" : \"int\" , \"nullable\" : False }}, { \"name\" : { \"type\" : \"string\" , \"nullable\" : True }}, { \"created_at\" : { \"type\" : \"datetime\" , \"nullable\" : False }}, ], ) server . start(catalog_emulation = True )","title":"Quick Start"},{"location":"catalog/#column-types","text":"Supported column type strings align with the Arrow types used by Riffq: int , float , bool , string / str , date , datetime These types inform clients about your table shape; your actual query results can be produced by any engine (DuckDB, Polars, Pandas, etc.) as Arrow.","title":"Column Types"},{"location":"catalog/#discovering-from-an-engine","text":"For real data sources, enumerate schemas/tables/columns dynamically and register them. For example with DuckDB (pseudo-code): def map_type (duckdb_type: str ) -> str : t = duckdb_type . upper() if \"INT\" in t: return \"int\" if any (x in t for x in [ \"DOUBLE\" , \"DECIMAL\" , \"REAL\" , \"FLOAT\" ]): return \"float\" if \"BOOL\" in t: return \"bool\" if t == \"DATE\" : return \"date\" if \"TIMESTAMP\" in t or \"DATETIME\" in t: return \"datetime\" return \"string\" server . register_database( \"duckdb\" ) for schema_name, table_name in list_tables_from_duckdb(): server . register_schema( \"duckdb\" , schema_name) columns = [] for col_name, dt, is_nullable in list_columns(schema_name, table_name): columns . append({col_name: { \"type\" : map_type(dt), \"nullable\" : is_nullable}}) server . register_table( \"duckdb\" , schema_name, table_name, columns) server . start(catalog_emulation = True )","title":"Discovering From an Engine"},{"location":"catalog/#examples","text":"For a minimal end-to-end example that registers a database, schema, and table and asserts they appear via pg_catalog , see: tests/test_register_catalog.py def main (): server = riffq . RiffqServer( \"127.0.0.1:5444\" , connection_cls = Connection) # Register catalog: logical databases redis0..redis2 (limited for illustration). # Under each, register schema \"public\" and expose each Redis hash key as a # table with (key,value). Increase the range below in real deployments. # schema \"public\" and expose each Redis hash key as a table with (key,value). for db_index in range ( 3 ): db_name = f\"redis { db_index } \" r = redis . Redis(host = \"localhost\" , port =6379 , db = db_index, password = None , decode_responses = True ) server . register_database(db_name) server . register_schema(db_name, \"public\" ) # Discover only hash keys. Uses SCAN TYPE hash (server-side filter) # so we don't issue a TYPE per key. Still a best-effort scan. for k in r . scan_iter(match = \"*\" , _type = \"hash\" ): server . register_table( db_name, \"public\" , str (k), [ { \"key\" : { \"type\" : \"string\" , \"nullable\" : False }}, { \"value\" : { \"type\" : \"string\" , \"nullable\" : True }}, ], ) When you start the server and connect with psql you can see the tables user=> \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+-------------+-------------+------------------- postgres | postgres | UTF8 | nl_NL.UTF-8 | nl_NL.UTF-8 | redis0 | postgres | UTF8 | C | C | redis1 | postgres | UTF8 | C | C | redis2 | postgres | UTF8 | C | C | template0 | postgres | UTF8 | nl_NL.UTF-8 | nl_NL.UTF-8 | template1 | postgres | UTF8 | nl_NL.UTF-8 | nl_NL.UTF-8 | (6 rows) user=> \\c redis0 Password: psql (14.17 (Homebrew), server 17.4.0) WARNING: psql major version 14, server major version 17. Some psql features might not work. You are now connected to database \"redis0\" as user \"user\". redis0=> \\dt List of relations Schema | Name | Type | Owner --------+--------+-------+---------- public | myhash | table | postgres public | test | table | postgres public | test2 | table | postgres public | test3 | table | postgres (4 rows) redis0=> \\d myhash Table \"public.myhash\" Column | Type | Collation | Nullable | Default --------+------+-----------+----------+--------- key | text | | not null | value | text | | | redis0=> \\d myhash Table \"public.myhash\" Column | Type | Collation | Nullable | Default --------+------+-----------+----------+--------- key | text | | not null | value | text | | | ; pg_catalog_rs has all pg_catalog tables ; for example you can select tables directly from pg_class redis0=> SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE c.relkind = 'r' AND n.nspname = 'public'; relname --------- myhash test2 test test3 (4 rows) ; or you can use ::regclass or ::oid type conversions as in ; real postgresql pg_catalog redis0=> SELECT oid,relname,reltype,relnamespace FROM pg_class WHERE oid = 'myhash'::oid; oid | relname | reltype | relnamespace -------+---------+---------+-------------- 50010 | myhash | 50011 | 2200 (1 row)","title":"Examples"},{"location":"catalog/#api-reference","text":"","title":"API Reference"},{"location":"catalog/#register-a-logical-database-name","text":"RiffqServer . register_database(database_name: str ) -> None :","title":"Register a logical database name"},{"location":"catalog/#register-a-schema-under-a-previously-registered-database","text":"RiffqServer . register_schema(database_name: str , schema_name: str ) -> None :","title":"Register a schema under a previously registered database."},{"location":"catalog/#register-a-table-and-its-columns","text":"Each column is { name: {\"type\": <str>, \"nullable\": <bool>} } . RiffqServer . register_table(database_name: str , schema_name: str , table_name: str , columns: list [ dict ]) -> None :","title":"Register a table and its columns."},{"location":"changelog/","text":"This file captures notable updates to the project and documentation. Replace the placeholder entries with real releases as they happen. Unreleased Added MkDocs-based documentation scaffolding with API reference generation. Created starter guides for onboarding, FAQs, and release tracking. 0.1.0 - Initial release Bootstrapped the project with Rust and Python integration.","title":"Changelog"},{"location":"changelog/#unreleased","text":"Added MkDocs-based documentation scaffolding with API reference generation. Created starter guides for onboarding, FAQs, and release tracking.","title":"Unreleased"},{"location":"changelog/#010-initial-release","text":"Bootstrapped the project with Rust and Python integration.","title":"0.1.0 - Initial release"},{"location":"faq/","text":"How do I rebuild the documentation? Run make docs to produce the static site in the site/ directory. Use make server-docs while editing to get live reloads at http://localhost:8000 . Where do the API docs come from? The API documentation is powered by mkdocstrings . It inspects the Python code in pysrc/riffq and renders docstrings into pages during the build. Can I document Rust code too? MkDocs primarily targets Python, but you can link to Rust documentation hosted elsewhere or generated via cargo doc . Who maintains the documentation? The Riffq engineering team owns the documentation. Contributions are welcome\u2014please submit a pull request with your updates.","title":"FAQ"},{"location":"faq/#how-do-i-rebuild-the-documentation","text":"Run make docs to produce the static site in the site/ directory. Use make server-docs while editing to get live reloads at http://localhost:8000 .","title":"How do I rebuild the documentation?"},{"location":"faq/#where-do-the-api-docs-come-from","text":"The API documentation is powered by mkdocstrings . It inspects the Python code in pysrc/riffq and renders docstrings into pages during the build.","title":"Where do the API docs come from?"},{"location":"faq/#can-i-document-rust-code-too","text":"MkDocs primarily targets Python, but you can link to Rust documentation hosted elsewhere or generated via cargo doc .","title":"Can I document Rust code too?"},{"location":"faq/#who-maintains-the-documentation","text":"The Riffq engineering team owns the documentation. Contributions are welcome\u2014please submit a pull request with your updates.","title":"Who maintains the documentation?"},{"location":"getting-started/","text":"This guide shows the fastest path to expose data over PostgreSQL using Riffq. You will: Subclass riffq.BaseConnection Implement handle_auth and handle_query Register your connection with riffq.RiffqServer For a deeper tour (extra callbacks, TLS), see the sections below. Install pip install riffq --pre Minimal server The smallest useful server authenticates clients and responds to queries. Below we implement a toy handler that answers a couple of fixed SQLs; extend as needed. import riffq import pyarrow as pa class Connection (riffq . BaseConnection): def handle_auth ( self , user, password, host, database = None , callback = callable ): # Accept a single demo user callback(user == \"user\" and password == \"secret\" ) def handle_query ( self , sql, callback = callable , ** kwargs): q = sql . strip() . lower() if q == \"select 1\" : batch = self . arrow_batch([pa . array([ 1 ])], [ \"one\" ]) self . send_reader(batch, callback) elif q == \"select 'ok' as status\" : batch = self . arrow_batch([pa . array([ \"ok\" ])], [ \"status\" ]) self . send_reader(batch, callback) else : # Send a simple error tuple (severity, code, message) callback(( \"ERROR\" , \"42601\" , \"unsupported demo query\" ), is_error = True ) server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . start() Connect using any PostgreSQL client: psql -h 127 .0.0.1 -p 5433 -U user Password for user user: secret Try: select 1 ; select 'ok' as status; RiffqServer creates a new instance from connection_cls class, so for each connected client/user you will have another instance. Using a real engine (DuckDB example) For non\u2011trivial SQL, delegate to your favorite engine. This version runs queries in a thread pool and returns Arrow results directly. import logging , duckdb , pyarrow as pa , riffq logging . basicConfig(level = logging . INFO) class Connection (riffq . BaseConnection): def handle_auth ( self , user, password, host, database = None , callback = callable ): callback(user == \"user\" and password == \"secret\" ) def _exec ( self , sql, callback): cur = duckdb_con . cursor() try : reader = cur . execute(sql) . fetch_record_batch() self . send_reader(reader, callback) except Exception as exc: logging . exception( \"query error\" ) callback(( \"ERROR\" , \"XX000\" , str (exc)), is_error = True ) def handle_query ( self , sql, callback = callable , ** kwargs): self . executor . submit( self . _exec, sql, callback) duckdb_con = duckdb . connect() server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . start() Returning errors If you call the callback on handle_query with is_error=True, the client will receive an error. Error codes are defined on here https://www.postgresql.org/docs/current/errcodes-appendix.html For quick ref. error code description 3D000 invalid catalog name 3F000 invalid schema name 42601 syntax_error 42P01 undefined_table 42703 undefined_column XX000 internal error Although these error codes don't show up on psql and various clients, some clients might be using these codes. Extra callbacks handle_connect Admit/deny connections (e.g., IP allowlist). Call callback(True) to accept. def handle_connect (ip, port, callback): return callback( True ) For example you can blacklist an ip address here. handle_disconnect cleanup on client disconnect. def handle_disconnect (ip, port, callback): # close open files etc. return callback() Context and Connection Id As mentioned in each connection, we create a new Connection instance. This creates a context. For example you'd want to direct queries by \"current database\" from sqlglot import parse_one, exp class Connection (riffq . BaseConnection): database = None def handle_auth ( self , user, password, host, database = None , callback = callable ): # Accept a single demo user self . database = database callback(user == \"user\" and password == \"secret\" ) def handle_query ( self , sql, callback = callable , ** kwargs): # check if \"use databasename\" statement is coming sql_ast = parse_one(sql, read = \"postgres\" ) if isinstance (sql_ast, exp . Use): target_database = sql_ast . this . name self . database = target_database # when switching a database, we don't return data, just a tag return callback( \"OK\" , is_tag = True ) # now you can dispatch by current user's database name if self . database == \"main\" : ... elif self . database = \"remote\" : ... else : callback(( \"ERROR\" , \"3D000\" , \"unknown database\" ), is_error = True ) server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . start() Connection id Sometimes this encapsulation may not be enough. So we also have an auto incrementing conn_id for each new connection. One example for this using external resources with one-on-one mapping. Say you build a postgresql frontend for redis import redis from sqlglot import parse_one, exp redis_connections = defaultdict( lambda : redis . Redis(host = \"localhost\" , port =6379 , db =0 , password = None )) class Connection (riffq . BaseConnection): def handle_query ( self , sql, callback = callable , ** kwargs): # get the existing or a new connection to redis for this conn_id redis_conn = redis_connections[ self . conn_id] parsed = parse_one(sql) if isinstance (parsed, exp . Select): # get which hashset from \"select key, value from hashset\" pattern # we can use tablename as hashset key tables = list (parsed . find_all(exp . Table)) if len (tables) != 1 : return callback( ... , is_error = True ) batch = self . arrow_batch([pa . array([ 1 ])], [ \"key\" , \"value\" ]) return self . send_reader(batch, callback) For a more complete example of accessing Redis with the PostgreSQL protocol, see the Redis example: psql_redis.py Catalog Emulation Many PostgreSQL clients discover databases, schemas, and tables by querying pg_catalog . Riffq can emulate pg_catalog and information_schema by using pg_catalog_rs , so your service can work as a real database server. Eg: you can connect dbeaver to your service. To use it: Call register_database , register_schema , and register_table to declare what you want to expose. Start the server with catalog_emulation=True . Example: server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . register_database( \"mydb\" ) server . register_schema( \"mydb\" , \"public\" ) server . register_table( \"mydb\" , \"public\" , \"users\" , [ { \"id\" : { \"type\" : \"int\" , \"nullable\" : False }}, { \"name\" : { \"type\" : \"string\" , \"nullable\" : True }}, ], ) server . start(catalog_emulation = True ) For a full walkthrough, see Catalog Emulation . For a runnable example of registering databases, schemas, and tables, see the test: tests/test_register_catalog.py . TLS (SSL) Enable TLS with a certificate and key: openssl req -newkey rsa:2048 -nodes -keyout server.key \\ -x509 -days 1 -out server.crt -subj \"/CN=localhost\" server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . set_tls( \"server.crt\" , \"server.key\" ) server . start(tls = True ) Tips Use self.arrow_batch([...], names=[...]) to construct quick result sets. Use self.send_reader(reader, callback) to return a pyarrow.RecordBatchReader . The server creates one Connection instance per client and reuses it. See the README for a fuller example and more context.","title":"Getting Started"},{"location":"getting-started/#install","text":"pip install riffq --pre","title":"Install"},{"location":"getting-started/#minimal-server","text":"The smallest useful server authenticates clients and responds to queries. Below we implement a toy handler that answers a couple of fixed SQLs; extend as needed. import riffq import pyarrow as pa class Connection (riffq . BaseConnection): def handle_auth ( self , user, password, host, database = None , callback = callable ): # Accept a single demo user callback(user == \"user\" and password == \"secret\" ) def handle_query ( self , sql, callback = callable , ** kwargs): q = sql . strip() . lower() if q == \"select 1\" : batch = self . arrow_batch([pa . array([ 1 ])], [ \"one\" ]) self . send_reader(batch, callback) elif q == \"select 'ok' as status\" : batch = self . arrow_batch([pa . array([ \"ok\" ])], [ \"status\" ]) self . send_reader(batch, callback) else : # Send a simple error tuple (severity, code, message) callback(( \"ERROR\" , \"42601\" , \"unsupported demo query\" ), is_error = True ) server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . start() Connect using any PostgreSQL client: psql -h 127 .0.0.1 -p 5433 -U user Password for user user: secret Try: select 1 ; select 'ok' as status; RiffqServer creates a new instance from connection_cls class, so for each connected client/user you will have another instance.","title":"Minimal server"},{"location":"getting-started/#using-a-real-engine-duckdb-example","text":"For non\u2011trivial SQL, delegate to your favorite engine. This version runs queries in a thread pool and returns Arrow results directly. import logging , duckdb , pyarrow as pa , riffq logging . basicConfig(level = logging . INFO) class Connection (riffq . BaseConnection): def handle_auth ( self , user, password, host, database = None , callback = callable ): callback(user == \"user\" and password == \"secret\" ) def _exec ( self , sql, callback): cur = duckdb_con . cursor() try : reader = cur . execute(sql) . fetch_record_batch() self . send_reader(reader, callback) except Exception as exc: logging . exception( \"query error\" ) callback(( \"ERROR\" , \"XX000\" , str (exc)), is_error = True ) def handle_query ( self , sql, callback = callable , ** kwargs): self . executor . submit( self . _exec, sql, callback) duckdb_con = duckdb . connect() server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . start()","title":"Using a real engine (DuckDB example)"},{"location":"getting-started/#returning-errors","text":"If you call the callback on handle_query with is_error=True, the client will receive an error. Error codes are defined on here https://www.postgresql.org/docs/current/errcodes-appendix.html For quick ref. error code description 3D000 invalid catalog name 3F000 invalid schema name 42601 syntax_error 42P01 undefined_table 42703 undefined_column XX000 internal error Although these error codes don't show up on psql and various clients, some clients might be using these codes.","title":"Returning errors"},{"location":"getting-started/#extra-callbacks","text":"","title":"Extra callbacks"},{"location":"getting-started/#handle_connect","text":"Admit/deny connections (e.g., IP allowlist). Call callback(True) to accept. def handle_connect (ip, port, callback): return callback( True ) For example you can blacklist an ip address here.","title":"handle_connect"},{"location":"getting-started/#handle_disconnect","text":"cleanup on client disconnect. def handle_disconnect (ip, port, callback): # close open files etc. return callback()","title":"handle_disconnect"},{"location":"getting-started/#context-and-connection-id","text":"As mentioned in each connection, we create a new Connection instance. This creates a context. For example you'd want to direct queries by \"current database\" from sqlglot import parse_one, exp class Connection (riffq . BaseConnection): database = None def handle_auth ( self , user, password, host, database = None , callback = callable ): # Accept a single demo user self . database = database callback(user == \"user\" and password == \"secret\" ) def handle_query ( self , sql, callback = callable , ** kwargs): # check if \"use databasename\" statement is coming sql_ast = parse_one(sql, read = \"postgres\" ) if isinstance (sql_ast, exp . Use): target_database = sql_ast . this . name self . database = target_database # when switching a database, we don't return data, just a tag return callback( \"OK\" , is_tag = True ) # now you can dispatch by current user's database name if self . database == \"main\" : ... elif self . database = \"remote\" : ... else : callback(( \"ERROR\" , \"3D000\" , \"unknown database\" ), is_error = True ) server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . start()","title":"Context and Connection Id"},{"location":"getting-started/#connection-id","text":"Sometimes this encapsulation may not be enough. So we also have an auto incrementing conn_id for each new connection. One example for this using external resources with one-on-one mapping. Say you build a postgresql frontend for redis import redis from sqlglot import parse_one, exp redis_connections = defaultdict( lambda : redis . Redis(host = \"localhost\" , port =6379 , db =0 , password = None )) class Connection (riffq . BaseConnection): def handle_query ( self , sql, callback = callable , ** kwargs): # get the existing or a new connection to redis for this conn_id redis_conn = redis_connections[ self . conn_id] parsed = parse_one(sql) if isinstance (parsed, exp . Select): # get which hashset from \"select key, value from hashset\" pattern # we can use tablename as hashset key tables = list (parsed . find_all(exp . Table)) if len (tables) != 1 : return callback( ... , is_error = True ) batch = self . arrow_batch([pa . array([ 1 ])], [ \"key\" , \"value\" ]) return self . send_reader(batch, callback) For a more complete example of accessing Redis with the PostgreSQL protocol, see the Redis example: psql_redis.py","title":"Connection id"},{"location":"getting-started/#catalog-emulation","text":"Many PostgreSQL clients discover databases, schemas, and tables by querying pg_catalog . Riffq can emulate pg_catalog and information_schema by using pg_catalog_rs , so your service can work as a real database server. Eg: you can connect dbeaver to your service. To use it: Call register_database , register_schema , and register_table to declare what you want to expose. Start the server with catalog_emulation=True . Example: server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . register_database( \"mydb\" ) server . register_schema( \"mydb\" , \"public\" ) server . register_table( \"mydb\" , \"public\" , \"users\" , [ { \"id\" : { \"type\" : \"int\" , \"nullable\" : False }}, { \"name\" : { \"type\" : \"string\" , \"nullable\" : True }}, ], ) server . start(catalog_emulation = True ) For a full walkthrough, see Catalog Emulation . For a runnable example of registering databases, schemas, and tables, see the test: tests/test_register_catalog.py .","title":"Catalog Emulation"},{"location":"getting-started/#tls-ssl","text":"Enable TLS with a certificate and key: openssl req -newkey rsa:2048 -nodes -keyout server.key \\ -x509 -days 1 -out server.crt -subj \"/CN=localhost\" server = riffq . RiffqServer( \"127.0.0.1:5433\" , connection_cls = Connection) server . set_tls( \"server.crt\" , \"server.key\" ) server . start(tls = True )","title":"TLS (SSL)"},{"location":"getting-started/#tips","text":"Use self.arrow_batch([...], names=[...]) to construct quick result sets. Use self.send_reader(reader, callback) to return a pyarrow.RecordBatchReader . The server creates one Connection instance per client and reuses it. See the README for a fuller example and more context.","title":"Tips"}]}